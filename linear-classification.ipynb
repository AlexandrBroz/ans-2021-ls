{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LineÃ¡rnÃ­ klasifikace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ãškolem cviÄenÃ­ je naprogramovat lineÃ¡rnÃ­ klasifikÃ¡tor, kterÃ½ bude rozpoznÃ¡vat objekty z datasetu CIFAR-10. **VyuÅ¾ijeme k tomu knihovnu pytorch.**\n",
    "\n",
    "KromÄ› znÃ¡mÃ½ch knihoven numpy, matplotlib a torch budeme potÅ™ebovat nÃ¡sledujÃ­cÃ­:\n",
    "- torchvision ... rozÅ¡iÅ™ujÃ­cÃ­ pytorch balÃ­k pro pytorch obsahujÃ­cÃ­ datasety, funkce pro zpracovÃ¡nÃ­ obrÃ¡zkÅ¯ a pÅ™edtrÃ©novanÃ© modely konvoluÄnÃ­ch sÃ­tÃ­\n",
    "- tqdm ... vykresluje bÄ›hem vÃ½poÄtÅ¯ progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 12, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZpÅ¯sob naÄÃ­tÃ¡nÃ­ dat kompletnÄ› zÃ¡visÃ­ na zpÅ¯sobu, jakÃ½m byla uloÅ¾ena. Zde pouÅ¾ijeme populÃ¡rnÃ­ dataset CIFAR-10, kterÃ½ Äasto slouÅ¾Ã­ jako zÃ¡kladnÃ­ benchmark pro porovnÃ¡nÃ­ pÅ™Ã­nosu novÃ½ch algoritmÅ¯ vÅ¯Äi stÃ¡vajÃ­cÃ­m. Ãškolem je klasifikace obrÃ¡zkÅ¯ do jednÃ© z 10 tÅ™Ã­d.\n",
    "\n",
    "BalÃ­k torchvision podporuje nÄ›kterÃ© znamÃ© datasety, mezi nÄ›Å¾ patÅ™Ã­ i CIFAR-10. NemusÃ­me tedy data stahovat z internetu manuÃ¡lnÄ›, torchvision za nÃ¡s vÅ¡e obstarÃ¡ automaticky. Data uloÅ¾Ã­me do adresÃ¡Å™e `./data`. VÅ¡imnÄ›me si flagu `train=True`, kterÃ½ Å™Ã­kÃ¡, Å¾e se mÃ¡ naÄÃ­st trÃ©novacÃ­ mnoÅ¾ina datasetu CIFAR-10 (soubory `data_batch_*`).\n",
    "\n",
    "Tenhle komentÃ¡Å™ zmÄ›nÃ­m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba6acf5e2634399a59139282c45711d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True)\n",
    "trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VÃ½slednÃ½ objekt se chovÃ¡ jako `list`, byÅ¥ nenÃ­ jeho odvozeninou (subclass). Indexuje tedy prvky od nuly, mÃ¡ definovanou dÃ©lku skrze `__len__` a podporuje `__getitem__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zavola `__len__`\n",
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zavola `__getitem__` s parametrem (indexem) 5\n",
    "trainset[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak vidÃ­me, 6. prvek datasetu je *dvojice* sestÃ¡vajÃ­cÃ­ z obrÃ¡zku a jeho indexu tÅ™Ã­dy (label, target). ObrÃ¡zek je defaultnÄ› navrÃ¡cen jako typ `Image` knihovny Pillow (Python Imaging Library, PIL). Pokud je vÃ½stupem buÅˆky objekt tohoto typu, jupyter notebook to rozpoznÃ¡ a zobrazÃ­ ho jako obrÃ¡zek. `Image` mÃ¡ totiÅ¾ definovanou metodu `__html__`, jÃ­Å¾ dÃ¡ notebook pÅ™ednost pÅ™ed obvyklÃ½m `__repr__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainset[5][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objekt CIFAR datasetu obsahuje i textovÃ½ popis tÅ™Ã­d ve formÄ› pole (`list`) nÃ¡zvÅ¯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 6. prvku\n",
    "trainset.classes[trainset[5][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VÅ¡echny obrÃ¡zky CIFAR datasetu jsou uloÅ¾eny v atributu `.train_data`, coÅ¾ je 4D `numpy.ndarray`. PrvnÃ­ dimenze odpovÃ­dÃ¡ jednotlivÃ½m obrÃ¡zkÅ¯m, dalÅ¡Ã­ pak Å™Ã¡dkÅ¯m, sloupcÅ¯m a kanÃ¡lÅ¯m (RGB), tedy $50000 \\times 32 \\times 32 \\times 3$. Hodnoty jsou uloÅ¾eny jako datovÃ½ typ `uint8`, tedy v rozsahu 0...255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(trainset.data), trainset.data.shape, trainset.data.dtype, trainset.data.min(), trainset.data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PodobnÄ› vÅ¡echny labely jsou uloÅ¾eny v `.targets`, coÅ¾ je `list` ÄÃ­sel (`int`) o dÃ©lce poÄtu obrÃ¡zkÅ¯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(trainset.targets), len(trainset.targets), type(trainset.targets[0]), min(trainset.targets), max(trainset.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokud chceme obrÃ¡zkÅ¯ vykreslit vÃ­ce najednou, vhodnÄ›jÅ¡Ã­ pouÅ¾Ã­t matplotlib (pyplot). Pro kaÅ¾dou tÅ™Ã­du vykreslÃ­me po sloupcÃ­ch 10 pÅ™Ã­kladÅ¯, abychom vidÄ›li, jak data vlastnÄ› vypadajÃ­."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, cls in enumerate(trainset.classes):\n",
    "    # chceme pouze obrazky aktualni tridy a z nich nahodne vybereme 10\n",
    "    cls_ids = [j for j, y in enumerate(trainset.targets) if y == i]\n",
    "    draw_ids = np.random.choice(cls_ids, size=10)\n",
    "    \n",
    "    # pyplot podobne jako MATLAB nabizi funkci subplot pro vykresleni vice grafu do jednoho okna\n",
    "    for j, k in enumerate(draw_ids):\n",
    "        # vykresli 10x10 obrazku, poradi je po radcich, ovsem my budeme vykreslovat po sloupcich,\n",
    "        # tj. kazdy sloupec bude obsahovat 10 prikladu jedne ze trid\n",
    "        plt.subplot(10, 10, j * 10 + i + 1)\n",
    "        \n",
    "        # vyresli obrazek\n",
    "        plt.imshow(trainset.data[k])\n",
    "        \n",
    "        # nevykresluj popisky os\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # v prvnim radku pridame nazev grafu (obrazku)\n",
    "        if j == 0:\n",
    "            plt.title(cls, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TestovacÃ­/validaÄnÃ­ data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TestovacÃ­ data ze souboru `test_batch` naÄteme stejnÄ› jako trÃ©novacÃ­, pouze tentokrÃ¡t nastavÃ­me flag `train` na hodnotu `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True)\n",
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cls in enumerate(testset.classes):\n",
    "    # chceme pouze obrazky aktualni tridy a z nich nahodne vybereme 10\n",
    "    cls_ids = [j for j, y in enumerate(testset.targets) if y == i]\n",
    "    draw_ids = np.random.choice(cls_ids, size=10)\n",
    "    \n",
    "    # pyplot podobne jako MATLAB nabizi funkci subplot pro vykresleni vice grafu do jednoho okna\n",
    "    for j, k in enumerate(draw_ids):\n",
    "        # vykresli 10x10 obrazku, poradi je po radcich, ovsem my budeme vykreslovat po sloupcich,\n",
    "        # tj. kazdy sloupec bude obsahovat 10 prikladu jedne ze trid\n",
    "        plt.subplot(10, 10, j * 10 + i + 1)\n",
    "        \n",
    "        # vyresli obrazek\n",
    "        plt.imshow(testset.data[k])\n",
    "        \n",
    "        # nevykresluj popisky os\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # v prvnim radku pridame nazev grafu (obrazku)\n",
    "        if j == 0:\n",
    "            plt.title(cls, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matice trÃ©novacÃ­ch a validaÄnÃ­ch dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JelikoÅ¾ pouÅ¾ijeme jednoduchÃ½ lineÃ¡rnÃ­ klasifikÃ¡tor, data **pÅ™evedeme do maticovÃ© formy**, ve kterÃ© kaÅ¾dÃ½ Å™Ã¡dek reprezentuje jeden obrÃ¡zek. Pro lepÅ¡Ã­ numerickÃ© chovÃ¡nÃ­ data navÃ­c z rozsahu `0...255` a typu `uint8` pÅ™evedeme do rozsahu `0...1` a datovÃ©ho typu s plovoucÃ­ Å™Ã¡dovou ÄÃ¡rkou.\n",
    "\n",
    "### ValidaÄnÃ­ vs testovacÃ­ mnoÅ¾iny\n",
    "\n",
    "TestovacÃ­ sada, kterÃ¡ je v pÅ™Ã­padÄ› CIFAR-10 obsaÅ¾ena v souboru `cifar-10-batches-py/test_batch`, by sprÃ¡vnÄ› nemÄ›la bÃ½t pouÅ¾Ã­vÃ¡na pro validaci, tj. volbu modelu a ladÄ›nÃ­ hyperparametrÅ¯, ale pouze pro odhad ÃºspÄ›Å¡nosti natrÃ©novanÃ©ho klasifikÃ¡toru na nevidÄ›nÃ½ch datech. Pokud pouÅ¾ijeme testovacÃ­ data pro validaci, efektivnÄ› tÃ­m vyuÅ¾Ã­vÃ¡me informaci v nich obsaÅ¾enou pro uÄenÃ­ modelu. Takto dosaÅ¾enÃ¡ skÃ³re bychom proto nemÄ›li uvÃ¡dÄ›t jako odhad ÃºspÄ›Å¡nosti na nevidÄ›nÃ½ch datech, mÅ¯Å¾e bÃ½t totiÅ¾ pÅ™Ã­liÅ¡ optimistickÃ½."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevedeme na pytorch tensor\n",
    "X_train = torch.tensor(trainset.data)\n",
    "\n",
    "# na vychozi datovy typ (float nebo double, lze menit) a do rozsahu 0...1\n",
    "X_train = X_train.to(torch.get_default_dtype()) / 255.\n",
    "\n",
    "# reshape na matici s obrazky na radcich\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "X_train.dtype, X_train.shape, X_train.min(), X_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labely** trÃ©novacÃ­ch dat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(trainset.targets)\n",
    "y_train.dtype, y_train.shape, y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matice **validaÄnÃ­ch** dat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevedeme na pytorch tensor\n",
    "X_valid = torch.tensor(testset.data)\n",
    "\n",
    "# na vychozi datovy typ (float nebo double, lze menit) a do rozsahu 0...1\n",
    "X_valid = X_valid.to(torch.get_default_dtype()) / 255.\n",
    "\n",
    "# reshape na matici s obrazky na radcich\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], -1)\n",
    "\n",
    "X_valid.dtype, X_valid.shape, X_valid.min(), X_valid.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labely** validaÄnÃ­ch dat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = torch.tensor(testset.targets)\n",
    "y_valid.dtype, y_valid.shape, y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax (logistickÃ¡ regrese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PÅ™ipomeÅˆme, Å¾e logistickÃ¡ regrese je jednoduchÃ½ lineÃ¡rnÃ­ klasifikÃ¡tor s parametry:\n",
    "\n",
    "- vÃ¡hovÃ¡ matice $W$\n",
    "  - rozmÄ›r `rozmÄ›r_vstupu x poÄet_tÅ™Ã­d`\n",
    "  - inicializujeme na malÃ© nÃ¡hodnÃ© hodnoty\n",
    "  - v kÃ³du oznaÄÃ­me jako `W_smax` (vÃ¡hy softmaxu)\n",
    "- bias vektor $b$\n",
    "  - rozmÄ›r `poÄet_tÅ™Ã­d`\n",
    "  - inicializujeme na vektor nul\n",
    "  - v kÃ³du oznaÄÃ­me jako `b_smax` (bias softmaxu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# ZDE DOPLNIT\n",
    "\n",
    "W_smax = torch.randn(X_train.shape[1], len(trainset.classes))\n",
    "\n",
    "#################################################################\n",
    "\n",
    "W_smax.dtype, W_smax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# ZDE DOPLNIT\n",
    "\n",
    "b_smax = torch.randn(len(trainset.classes))\n",
    "\n",
    "#################################################################\n",
    "\n",
    "b_smax.dtype, b_smax.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrÃ©novÃ¡nÃ­ metodou online SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DopÅ™ednÃ½ prÅ¯chod\n",
    "1. Pokud mÃ¡me na vstupu *jeden* obrÃ¡zek $x$, vektor lineÃ¡rnÃ­ho skÃ³re pro jednotlivÃ© tÅ™Ã­dy je\n",
    "$$ s \\leftarrow W x + b $$\n",
    "a tedy $s \\in \\mathbb{R}^C$, kde $C$ znaÄÃ­ celkovÃ½ poÄet tÅ™Ã­d.\n",
    "\n",
    "2. Vektor skÃ³re $s$ dÃ¡le prochÃ¡zÃ­ softmaxem. ZÃ­skÃ¡me vektor $p$, ve kterÃ©m $i$-tÃ½ prvek znaÄÃ­ pravdÄ›podobnost, Å¾e $x$ patÅ™Ã­ do tÅ™Ã­dy $i$.\n",
    "$$ p \\leftarrow \\frac{\\exp{s}}{\\sum_{c=0}^{C-1}\\exp{s_c}} $$\n",
    "VÃ½slednÃ© $p$ mÃ¡ tedy stejnÃ½ rozmÄ›r jako $s$ a platÃ­ $\\sum_{c}p_c=1$.\n",
    "\n",
    "3. Zda a jak moc byla predikce sprÃ¡vnÃ¡ urÄÃ­ kriteriÃ¡lnÃ­ funkce (loss), tzv. cross entropy, kterÃ¡ ve speciÃ¡lnÃ­m pÅ™Ã­padÄ› klasifikace do jednÃ© z $C$ tÅ™Ã­d mÃ¡ tvar\n",
    "$$L \\leftarrow -\\log p_y$$\n",
    "kde $y\\in\\{1,\\ldots,C\\}$ je index tÅ™Ã­dy, do kterÃ© obrÃ¡zek ve skuteÄnosti patÅ™Ã­ (label/target obrÃ¡zku).\n",
    "\n",
    "##### Regularizace\n",
    "\n",
    "Regularizace penalizuje pÅ™Ã­liÅ¡ velkÃ© hodnoty vah $W$. NejÄastÄ›ji se setkÃ¡me s typem L2, u nÄ›jÅ¾ k vÃ½slednÃ© hodnotÄ› lossu pÅ™iÄÃ­tÃ¡me dodateÄnÃ½ Älen\n",
    "$$\\lambda\\sum_{ij}w_{ij}^2$$\n",
    "kde $w_{ij}$ je vÃ¡ha na $i$-tÃ©m Å™Ã¡dku a $j$-tÃ©m sloupci matice $W$ a $\\lambda$ je hyperparametr vyjadÅ™ujÃ­cÃ­ vÃ¡hu regularizace (v kÃ³du je $\\lambda$ oznaÄenÃ¡ jako promÄ›nnÃ¡ `l2_decay`).\n",
    "\n",
    "Pro lepÅ¡Ã­ monitoring hodnoty lossu **regularizaci nepÅ™iÄÃ­tejte**, ale drÅ¾te ji zvlÃ¡Å¡Å¥ v promÄ›nnÃ© `l2_val`.\n",
    "\n",
    "#### ZpÄ›tnÃ½ prÅ¯chod\n",
    "1. Vzorec pro gradient na $c$-tÃ½ Å™Ã¡dek vÃ¡hovÃ© *matice* je (Å™Ã¡dek pro sprÃ¡vnou tÅ™Ã­du se od ostatnÃ­ch liÅ¡Ã­)\n",
    "$$ \\frac{\\partial L}{\\partial w_c} \\leftarrow \\left(p_c - \\boldsymbol{1}(c=y)\\right) x^\\top $$\n",
    "\n",
    "2. Gradient na $c$-tÃ½ prvek bias *vektoru* (prvek pro sprÃ¡vnou tÅ™Ã­du se od ostatnÃ­ch liÅ¡Ã­)\n",
    "$$ \\frac{\\partial L}{\\partial b_c} \\leftarrow p_c - \\boldsymbol{1}(c=y) $$\n",
    "\n",
    "##### Regularizace\n",
    "\n",
    "Pokud pouÅ¾Ã­vÃ¡me regularizaci vah $W$, jeÅ¡tÄ› pÅ™ed updatem parametrÅ¯ $W$ a $b$ upravÃ­me ${\\partial L} / {\\partial W}$ gradientem regularizaÄnÃ­ho Älenu (ten zvlÃ¡dnete sami). NezapomeÅˆte na vÃ¡hu regularizace $\\lambda$.\n",
    "\n",
    "#### Gradient descent update \n",
    "\n",
    "1. Update vah $W$\n",
    "$$ W \\leftarrow W - \\gamma \\frac{\\partial L}{\\partial W} $$\n",
    "kde $\\gamma$ je velikost kroku gradient descentu (learning rate)\n",
    "\n",
    "2. Update biasu $b$\n",
    "$$ b \\leftarrow b - \\gamma \\frac{\\partial L}{\\partial b} $$\n",
    "\n",
    "### PoznÃ¡mky\n",
    "\n",
    "- PopsanÃ½ zpÅ¯sob a kostra kÃ³du odpovÃ­dÃ¡ trÃ©novÃ¡nÃ­ online variantou gradient descentu (stochastic gradient descent, SGD), tzn. update parametrÅ¯ nÃ¡sleduje po kaÅ¾dÃ©m vstupnÃ­m vektoru, nikoliv po zpracovÃ¡nÃ­ vÅ¡ech dat.\n",
    "- Ve vzoreÄcÃ­ch se pracuje s vektorem $x$ jako se sloupcem, ale data v `X_train` jsou po Å™Ã¡dcÃ­ch a matice vah $W$ mÃ¡ rozmÄ›r `rozmÄ›r_vstupu x poÄet_tÅ™Ã­d`. V kÃ³du proto budou vÃ½poÄty transponovanÃ©, tj. $s = x W + b$ a vzorec pro gradient na $c$-tÃ½ *Å™Ã¡dek* matice $W$ bude ve skuteÄnosti vzorec na $c$-tÃ½ sloupec!\n",
    "  \n",
    "  \"Proboha proÄ?\", ptÃ¡te se? Teorie vychÃ¡zÃ­ ze zavedenÃ© konvence v lineÃ¡rnÃ­ algebÅ™e, kde jsou vektory uvaÅ¾ovÃ¡ny jako sloupcovÃ© a strojovÃ© uÄenÃ­ tÃ­mto zpÅ¯sobem popisuje i vÄ›tÅ¡ina dopstupnÃ© literatury. Pro zachovÃ¡nÃ­ \"kompatibility\" materiÃ¡lÅ¯ tak postpujejme i zde. Tuto konvenci kdysi dÃ¡vno pÅ™evzal jazyk Fortran a v nÃ¡vaznosti na nÄ›j i MATLAB, a proto majÃ­ tyto jazyky matice uloÅ¾enÃ© po sloupcÃ­ch. V jazycÃ­ch jako Python (potaÅ¾mo v knihovnÃ¡ch numpy a pytorch) jsou vÅ¡ak matice tzv. row-major, a tedy daty uloÅ¾enÃ½mi typicky po Å™Ã¡dcÃ­ch, a bez transpozice rovnic by se musela transponovat data $x$, coÅ¾ by bylo vÃ½poÄetnÄ› neefektivnÃ­.\n",
    "  \n",
    "- VÄ›tÅ¡ina operacÃ­ (napÅ™. funkce `argmax`) v pytorchi vracÃ­ `torch.tensor`, i kdyÅ¾ je vÃ½sledkem jedinÃ© reÃ¡lnÃ© ÄÃ­slo. V takovÃ©m pÅ™Ã­padÄ› lze obvykle pÅ™evÃ©st na pythonovskÃ½ built-in typ jednoduÅ¡e jako napÅ™. `int(pytorch_tensor)`.\n",
    "\n",
    "- OdlaÄte trÃ©novacÃ­ cyklus nejprve pro `num_iters = 1`, pak teprve spusÅ¥te na velkÃ½ poÄet iteracÃ­ (napÅ™. roven poÄtu trÃ©novacÃ­ch obrÃ¡zkÅ¯ = 1 epocha). PokaÅ¾dÃ©, kdyÅ¾ nÄ›co selÅ¾e, sledujte hodnoty a tvar matic (vektorÅ¯) skÃ³re, vah apod. v jednotlivÃ½ch krocÃ­ch tak, Å¾e si vytvoÅ™Ã­te novou buÅˆku a prozkoumÃ¡te, co se s nimi dÄ›je.\n",
    "\n",
    "- Hyperparametry $\\gamma$ (`learning_rate`) a $\\lambda$ (`l2_decay`) nastavte na malÃ© hodnoty $\\ll 1$ a optimalizujte tak, abyste dosÃ¡hli co nejlepÅ¡Ã­ho skÃ³re na validaÄnÃ­ch datech. Krok gradient descentu `learning_rate` mÅ¯Å¾ete pÅ™i opakovanÃ½ch prÅ¯chodech daty (epochy) postupnÄ› sniÅ¾ovat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparametry\n",
    "learning_rate = 0.001\n",
    "l2_decay = 0.0001\n",
    "num_iters = X_train.shape[0]\n",
    "\n",
    "# akumulator\n",
    "num_correct = 0\n",
    "loss = 0.\n",
    "l2_val = 0.\n",
    "\n",
    "# hlavni trenovaci cyklus\n",
    "pb = tqdm.tnrange(num_iters)\n",
    "for n in pb:\n",
    "    # print(n)\n",
    "    # obrazek vybereme nahodne\n",
    "    idx = int(torch.randint(X_train.shape[0], (1,)))\n",
    "    \n",
    "    # ziskame data\n",
    "    xn = X_train[idx]\n",
    "    yn = y_train[idx]\n",
    "    \n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    # dopredny pruchod: linearni skore, sigmoida a loss\n",
    "    score = torch.mm(xn.reshape(1, -1), W_smax) #.reshape(-1, 1)\n",
    "    \n",
    "    exp_vars = torch.exp(score)\n",
    "    prob = exp_vars / torch.sum(exp_vars)\n",
    "    \n",
    "    loss +=   - torch.log(prob[0][yn]) \n",
    "    l2_val += l2_decay * torch.sum(torch.mul(W_smax, W_smax)) # dtto # W_smax**2\n",
    "    \n",
    "    # gradient na vahy\n",
    "    one_mat = torch.zeros(W_smax.shape[1])\n",
    "    one_mat[yn] = 1\n",
    "    d_ps = prob - one_mat\n",
    "    dW = torch.zeros(W_smax.shape[1], len(xn))\n",
    "    \n",
    "    # gradient na skore (clen $(ð‘ð‘âˆ’1(ð‘=ð‘¦))$ ve vzorecku dL/dw_c)\n",
    "    for c in range(W_smax.shape[1]):\n",
    "        num = prob[0][c]\n",
    "        if c == yn:\n",
    "            num -= 1\n",
    "        dW[c] = torch.mul(xn, num)\n",
    "    \n",
    "    # gradient na bias\n",
    "    db = d_ps\n",
    "    \n",
    "    # regularizace (volitelna; modifikuje gradient na vahy)\n",
    "    # dW += ...\n",
    "    \n",
    "    # update parametru\n",
    "    W_smax -= learning_rate*dW.t()\n",
    "    b_smax -= learning_rate*db[0]\n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    if score.argmax() == yn:\n",
    "        num_correct += 1\n",
    "    \n",
    "    # prubezny vypis\n",
    "    if n % 100 == 0:\n",
    "        pb.set_postfix(loss='{:.3f}'.format(float(loss / (n + 1))), acc='{:.3f}'.format(num_correct / (n + 1)))\n",
    "\n",
    "print('train accuracy: {}/{} = {:.1f} %'.format(num_correct, n, 100. * num_correct / n))\n",
    "print(float(loss) / n, float(l2_val) / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_smax_backuuuuup36_6 = W_smax.clone()\n",
    "b_smax_backup = b_smax.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_smax_backuuuuup35_5 = W_smax.clone()\n",
    "b_smax_backup_35_5 = b_smax.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validace\n",
    "\n",
    "\n",
    "NatrÃ©novanÃ½ klasifikÃ¡tor ovÄ›Å™Ã­me na validaÄnÃ­ (development) mnoÅ¾inÄ›. IdeÃ¡lnÄ› bychom mÄ›li dosÃ¡hnout stejnÃ© ÃºspÄ›Å¡nosti jako na trÃ©novacÃ­ sadÄ›, pravdÄ›podobnÄ› tomu tak ale nebude. ProÄ?\n",
    "\n",
    "**Postup je jednoduÅ¡Å¡Ã­ neÅ¾ v pÅ™Ã­padÄ› trÃ©novÃ¡nÃ­:**\n",
    "1. DopÅ™ednÃ½ prÅ¯chod\n",
    "$$ s \\leftarrow W x + b $$\n",
    "\n",
    "2. NenÃ­ tÅ™eba poÄÃ­tat pravdÄ›podobnosti. Softmax pouze znormalizuje skÃ³re tak, aby vÃ½slednÃ¡ ÄÃ­sla tvoÅ™ila rozdÄ›lenÃ­ pravdÄ›podobnosti. Pokud je ve vektoru $s$ max. hodnota na pozici $i$, pak bude $i$-tÃ½ prvek max. i ve vektoru $p$. StaÄÃ­ tedy porovnat index $i$ s labelem obrÃ¡zku $y$ a pokud se rovnajÃ­, je predikce sprÃ¡vnÃ¡, jinak ne. VÃ½slednÃ© skÃ³re pak bude podÃ­l sprÃ¡vnÄ› klasifikovanÃ½ch obrÃ¡zkÅ¯ vÅ¯Äi celkovÃ©mu poÄtu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_correct = 0\n",
    "\n",
    "for n in tqdm.tnrange(X_valid.shape[0]):   \n",
    "    # ziskame data\n",
    "    xn = X_valid[n]\n",
    "    yn = y_valid[n]\n",
    "    \n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    # dopredny pruchod: linearni skore, sigmoida a loss\n",
    "    score = torch.mm(xn.reshape(1, -1), W_smax)\n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    if score.argmax() == yn:\n",
    "        num_correct += 1\n",
    "\n",
    "print('val accuracy: {}/{} = {:.1f} %'.format(num_correct, n, 100. * num_correct / n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weston-Watkins SVM\n",
    "\n",
    "Jak jsme si ukÃ¡zali v pÅ™ednÃ¡Å¡ce, SVM je softmaxu velmi podobnÃ©. Z pohledu neuronovÃ½ch sÃ­tÃ­ se liÅ¡Ã­ pouze zpÅ¯sobem vÃ½poÄtu lossu - mÃ­sto cross entropy pouÅ¾ijeme hinge loss definovanÃ½ jako\n",
    "$$L = \\sum_{c\\ne y}\\max(0, 1 + s_c - s_y)$$\n",
    "kde $s$ je vektor lineÃ¡rnÃ­ch skÃ³re $s=Wx + b$.\n",
    "\n",
    "Gradient na vÃ¡hy pak je\n",
    "$$\\frac{\\partial L}{\\partial w_y} = -\\sum_{c\\ne y}\\boldsymbol{1}(1 + s_c - s_y > 0)x$$\n",
    "$$\\frac{\\partial L}{\\partial w_{c\\ne y}} = \\boldsymbol{1}(1 + s_c - s_y > 0)x$$\n",
    "a pro biasy podobnÄ›, pouze bez nÃ¡sobenÃ­ $x$ (na konci)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# ZDE DOPLNIT\n",
    "\n",
    "W_svm = torch.randn(X_train.shape[1], len(trainset.classes))\n",
    "\n",
    "#################################################################\n",
    "\n",
    "W_svm.dtype, W_svm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# ZDE DOPLNIT\n",
    "\n",
    "b_svm = torch.randn(len(trainset.classes))\n",
    "\n",
    "#################################################################\n",
    "\n",
    "b_svm.dtype, b_svm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrÃ©novÃ¡nÃ­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# hyperparametry\n",
    "learning_rate = 0.001\n",
    "l2_decay = 0.001\n",
    "num_iters = X_train.shape[0]\n",
    "\n",
    "# akumulator\n",
    "num_correct = 0\n",
    "loss = 0.\n",
    "l2_val = 0.\n",
    "\n",
    "# hlavni trenovaci cyklus\n",
    "pb = tqdm.tnrange(num_iters)\n",
    "for n in pb:\n",
    "    # obrazek vybereme nahodne\n",
    "    idx = int(torch.randint(X_train.shape[0], (1,)))\n",
    "    \n",
    "    # ziskame data\n",
    "    xn = X_train[idx]\n",
    "    yn = y_train[idx]\n",
    "    \n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    # dopredny pruchod: linearni skore, sigmoida a loss\n",
    "    score = torch.mm(xn.reshape(1, -1), W_svm)\n",
    "    \n",
    "    eps_nc = torch.zeros(score.shape[1])\n",
    "    L = 0\n",
    "    for i in range(score.shape[1]):\n",
    "        if i == yn:\n",
    "            continue\n",
    "        eps_nc[i] = (score[0, i] - score[0, yn] + 1).item()\n",
    "        L += max(0, eps_nc[i])\n",
    "            \n",
    "    #margin = \n",
    "    loss += L\n",
    "    l2_val += l2_decay * torch.sum(torch.mul(W_svm, W_svm))\n",
    "    \n",
    "    # gradient na bias\n",
    "    db = torch.zeros(W_svm.shape[1])\n",
    "    \n",
    "    # gradient na vahy\n",
    "    \n",
    "    dW = torch.zeros(W_svm.shape[1], W_svm.shape[0])\n",
    "    for i in range(dW.shape[0]):\n",
    "        if i == yn:\n",
    "            calc_sum = torch.zeros(xn.shape[0])\n",
    "            b_sum = 0\n",
    "            for j in range(eps_nc.shape[0]):\n",
    "                if j == yn:\n",
    "                    continue\n",
    "                if eps_nc[j] > 0:\n",
    "                    calc_sum += xn\n",
    "                    b_sum+=1\n",
    "            dW[i] = -calc_sum\n",
    "            db[i] = -b_sum\n",
    "        if eps_nc[i] > 0:\n",
    "            dW[i] = xn\n",
    "            db[i] = 1\n",
    "    \n",
    "    # regularizace (modifikuje gradient na vahy)\n",
    "    #dW += \n",
    "    \n",
    "    # update parametru\n",
    "    W_svm -= learning_rate*dW.t()\n",
    "    b_svm -= learning_rate*db\n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    if score.argmax() == yn:\n",
    "        num_correct += 1\n",
    "    \n",
    "    # prubezny vypis\n",
    "    if n % 100 == 0:\n",
    "        pb.set_postfix(loss='{:.3f}'.format(float(loss / (n + 1))), acc='{:.3f}'.format(num_correct / (n + 1)))\n",
    "\n",
    "print('train accuracy: {}/{} = {:.1f} %'.format(num_correct, num_iters, 100. * num_correct / num_iters))\n",
    "print(float(loss) / num_iters, float(l2_val) / num_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_correct = 0\n",
    "\n",
    "for n in tqdm.tnrange(X_valid.shape[0]):   \n",
    "    # ziskame data\n",
    "    xn = X_valid[n]\n",
    "    yn = y_valid[n]\n",
    "    \n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    # dopredny pruchod: linearni skore, sigmoida a loss\n",
    "    score = torch.mm(xn.reshape(1, -1), W_svm)\n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    if score.argmax() == yn:\n",
    "        num_correct += 1\n",
    "\n",
    "print('val accuracy: {}/{} = {:.1f} %'.format(num_correct, X_valid.shape[0], 100. * num_correct / X_valid.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
